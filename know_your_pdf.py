# -*- coding: utf-8 -*-
"""Know your PDF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s1ckUZelwJKebn5_fbFBYl4qKwS6NwkX
"""

!pip install -q transformers datasets sentence-transformers langchain faiss-cpu pypdf2 auto-gptq langchain-community

import torch
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

from PyPDF2 import PdfReader

# Load and parse the PDF
def load_pdf(file_path):
    pdf_reader = PdfReader(file_path)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

# Split document into chunks
def split_text_into_chunks(text, chunk_size=500):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=50
    )
    return text_splitter.split_text(text)

# Load PDF and split into chunks
pdf_path = "/content/Rahul_Shah_Resume.pdf"  # Upload a sample PDF to Colab
raw_text = load_pdf(pdf_path)
chunks = split_text_into_chunks(raw_text)
print(f"Total chunks created: {len(chunks)}")

# Load BGE embedding model
embedding_model_name = "BAAI/bge-base-en-v1.5"
#embedding_model_name = "text-embedding-ada-002"
embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_name)

# Create FAISS Vector Store
vector_store = FAISS.from_texts(chunks, embedding_function)
print("Embeddings generated and stored in FAISS.")



# Load tokenizer and model
model_name = "meta-llama/Llama-3.2-3B-Instruct"
#model_name = "TheBloke/Llama-3B-Instruct-GPTQ"  # Lightweight version
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", torch_dtype=torch.float16)

# Create LLM pipeline
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_length=1024,
    do_sample=True,
    temperature=0.7
)

llm = HuggingFacePipeline(pipeline=pipe)

# Define Retrieval-based QA Chain
retriever = vector_store.as_retriever(search_type="similarity", search_k=5)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type="stuff")

query = "how many total years of experience does rahul hemal shah have"
response = qa_chain.run(query)
print(f"Response: {response}")

query = "What are the characterstic features of rahul"
response = qa_chain.run(query)
print(f"Response: {response}")

query = "What kind of applications has Rahul Hemal Shah built using ReactJS?"
response = qa_chain.run(query)
print(f"Response: {response}")

!pip install -q rouge_score sacrebleu

import time
import numpy as np
from langchain.evaluation.qa import QAEvalChain
from langchain.schema import Document
from langchain.vectorstores import FAISS
from sklearn.metrics import precision_score, recall_score
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from rouge_score import rouge_scorer
from sacrebleu import corpus_bleu

reference_data = [
    {
        "question": "What kind of applications has Rahul Hemal Shah built using ReactJS?",
        "reference": "Rahul Hemal Shah has built feature-rich frontend portals and enterprise-level applications using ReactJS, Angular, React Router, Redux, and PowerApps. He developed interactive UIs with reusable components, integrated REST APIs seamlessly, and ensured scalability and performance optimization across applications in his roles at SLB."
    },
    {
        "question": "Which machine learning libraries has Rahul Hemal Shah used in his projects?",
        "reference": "Rahul Hemal Shah has extensively worked with machine learning libraries such as PyTorch, TensorFlow, and Scikit-learn for developing classification, regression, and anomaly detection models. He also leveraged Pandas and NumPy for data preprocessing and feature engineering, and used OpenCV for image processing tasks in computer vision projects."
    },
    {
        "question": "Can you summarize Rahul Hemal Shah's contribution to the SnapScore project in one sentence?",
        "reference": "Rahul Hemal Shah developed SnapScore, an innovative NLP-driven text-to-image evaluation system that utilized ResNet and LSTM architectures to assess the semantic accuracy of generated image captions, enhancing the reliability of text-to-image models."
    },
    {
        "question": "Has Rahul Hemal Shah published any research in Springer? If yes, what was it about?",
        "reference": "Yes, Rahul Hemal Shah has published two research papers in Springer. His first paper focused on anomaly detection in drone-captured images using machine learning and deep learning models, while the second paper proposed a two-level authentication system for secure gate entry in a localized campus network."
    },
    {
        "question": "Which internship gave Rahul Hemal Shah experience with SOAP APIs?",
        "reference": "Rahul has experience with RestAPI's but not with SOAP API's"
    },
    {
        "question": "What programming languages is Rahul Hemal Shah comfortable using across both frontend and backend development?",
        "reference": "Rahul Hemal Shah is proficient in a variety of programming languages across full-stack development, including Python, React, Angular, JavaScript, TypeScript, C#, Java, SQL, GraphQL and C++. He has used these languages to develop frontend interfaces, backend APIs, and implement efficient database queries."
    },
    {
        "question": "How has Rahul Hemal Shah contributed to improving test coverage in his professional roles?",
        "reference": "Rahul Hemal Shah significantly improved unit test coverage to 65% in his role at SLB by implementing robust unit and integration tests. He also set up CI/CD pipelines with automated testing using Jenkins and Azure DevOps, reducing the occurrence of production bugs and ensuring seamless application delivery."
    },
    {
        "question": "Which tools has Rahul Hemal Shah used for version control and CI/CD?",
        "reference": "Rahul Hemal Shah has utilized Git extensively for version control, managing codebases and enabling smooth collaboration across teams. He has also worked with CI/CD tools such as Azure DevOps, Jenkins, and GitHub Actions to automate build, test, and deployment processes, ensuring streamlined delivery of enterprise applications."
    },
    {
        "question": "What does Rahul Hemal Shah's current academic coursework focus on at UMass Amherst?",
        "reference": "Rahul Hemal Shah's current academic coursework at UMass Amherst includes a rigorous curriculum focused on Machine Learning, Advanced Algorithms, Natural Language Processing, Systems for Data Science, and Information Retrieval. His coursework emphasizes theoretical foundations, hands-on project work, and real-world applications in AI and data science."
    },
    {
        "question": "What deep learning models or architectures has Rahul Hemal Shah worked with?",
        "reference": "Rahul Hemal Shah has worked with deep learning models such as Convolutional Neural Networks (CNNs) for image classification, Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) models for sequence prediction tasks, and transformer-based architectures such as BERT and GPT for natural language understanding and generation."
    }
]

def calculate_precision_recall(query, relevant_chunks, retrieved_chunks):
    relevant_set = set(relevant_chunks)
    retrieved_set = set(retrieved_chunks)

    # Precision = Relevant retrieved / Total retrieved
    precision = len(relevant_set.intersection(retrieved_set)) / len(retrieved_set) if len(retrieved_set) > 0 else 0

    # Recall = Relevant retrieved / Total relevant
    recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set) if len(relevant_set) > 0 else 0

    return precision, recall

retrieved_results = []
for item in reference_data:
    query = item["question"]
    relevant_chunks = [item["reference"]]  # Ideal relevant chunk
    retrieved_chunks = [doc.page_content for doc in retriever.get_relevant_documents(query)]

    precision, recall = calculate_precision_recall(query, relevant_chunks, retrieved_chunks)
    retrieved_results.append({
        "query": query,
        "retrieved_chunks": retrieved_chunks,
        "precision": precision,
        "recall": recall
    })

# Display results
for result in retrieved_results:
    print(f"Query: {result['query']}")
    print(f"Precision: {result['precision']:.4f}")
    print(f"Recall: {result['recall']:.4f}\n")

def calculate_bleu(reference_texts, generated_texts):
    return corpus_bleu(generated_texts, [reference_texts]).score

def calculate_rouge(reference_text, generated_text):
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
    scores = scorer.score(reference_text, generated_text)
    return scores

bleu_scores, rouge_scores = [], []
for item in reference_data:
    query = item["question"]
    reference_text = item["reference"]

    # Generate response using RAG pipeline
    generated_response = qa_chain.run(query)

    # Calculate BLEU and ROUGE scores
    bleu_score = calculate_bleu(reference_text, generated_response)
    rouge_score = calculate_rouge(reference_text, generated_response)

    # Store scores
    bleu_scores.append(bleu_score)
    rouge_scores.append(rouge_score)

    print(f"Query: {query}")
    print(f"Generated: {generated_response}")
    print(f"BLEU Score: {bleu_score:.2f}")
    print(f"ROUGE-1: {rouge_score['rouge1'].fmeasure:.2f}")
    print(f"ROUGE-2: {rouge_score['rouge2'].fmeasure:.2f}")
    print(f"ROUGE-L: {rouge_score['rougeL'].fmeasure:.2f}\n")

def track_latency(query):
    # Measure retrieval time
    start_time = time.time()
    retrieved_chunks = retriever.get_relevant_documents(query)
    retrieval_time = time.time() - start_time

    # Measure generation time
    start_time = time.time()
    response = qa_chain.run(query)
    generation_time = time.time() - start_time

    return retrieval_time, generation_time

latency_results = []
for item in reference_data:
    query = item["question"]
    retrieval_time, generation_time = track_latency(query)

    latency_results.append({
        "query": query,
        "retrieval_time": retrieval_time,
        "generation_time": generation_time
    })

# Display latency results
for result in latency_results:
    print(f"Query: {result['query']}")
    print(f"Retrieval Time: {result['retrieval_time']:.2f} seconds")
    print(f"Generation Time: {result['generation_time']:.2f} seconds\n")

!pip install -q bert-score scikit-learn

import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
from bert_score import score as bert_score
from sklearn.metrics import f1_score

reference_data = [
    {
        "question": "What kind of applications has Rahul Hemal Shah built using ReactJS?",
        "reference": "Rahul Hemal Shah has built feature-rich frontend portals and enterprise-level applications using ReactJS, Angular, React Router, Redux, and PowerApps. He developed interactive UIs with reusable components, integrated REST APIs seamlessly, and ensured scalability and performance optimization across applications in his roles at SLB."
    },
    {
        "question": "Which machine learning libraries has Rahul Hemal Shah used in his projects?",
        "reference": "Rahul Hemal Shah has extensively worked with machine learning libraries such as PyTorch, TensorFlow, and Scikit-learn for developing classification, regression, and anomaly detection models. He also leveraged Pandas and NumPy for data preprocessing and feature engineering, and used OpenCV for image processing tasks in computer vision projects."
    },
    {
        "question": "Can you summarize Rahul Hemal Shah's contribution to the SnapScore project in one sentence?",
        "reference": "Rahul Hemal Shah developed SnapScore, an innovative NLP-driven text-to-image evaluation system that utilized ResNet and LSTM architectures to assess the semantic accuracy of generated image captions, enhancing the reliability of text-to-image models."
    },
    {
        "question": "Has Rahul Hemal Shah published any research in Springer? If yes, what was it about?",
        "reference": "Yes, Rahul Hemal Shah has published two research papers in Springer. His first paper focused on anomaly detection in drone-captured images using machine learning and deep learning models, while the second paper proposed a two-level authentication system for secure gate entry in a localized campus network."
    },
    {
        "question": "Which internship gave Rahul Hemal Shah experience with SOAP APIs?",
        "reference": "Rahul has experience with RestAPI's but not with SOAP API's"
    },
    {
        "question": "What programming languages is Rahul Hemal Shah comfortable using across both frontend and backend development?",
        "reference": "Rahul Hemal Shah is proficient in a variety of programming languages across full-stack development, including Python, React, Angular, JavaScript, TypeScript, C#, Java, SQL, GraphQL and C++. He has used these languages to develop frontend interfaces, backend APIs, and implement efficient database queries."
    },
    {
        "question": "How has Rahul Hemal Shah contributed to improving test coverage in his professional roles?",
        "reference": "Rahul Hemal Shah significantly improved unit test coverage to 65% in his role at SLB by implementing robust unit and integration tests. He also set up CI/CD pipelines with automated testing using Jenkins and Azure DevOps, reducing the occurrence of production bugs and ensuring seamless application delivery."
    },
    {
        "question": "Which tools has Rahul Hemal Shah used for version control and CI/CD?",
        "reference": "Rahul Hemal Shah has utilized Git extensively for version control, managing codebases and enabling smooth collaboration across teams. He has also worked with CI/CD tools such as Azure DevOps, Jenkins, and GitHub Actions to automate build, test, and deployment processes, ensuring streamlined delivery of enterprise applications."
    },
    {
        "question": "What does Rahul Hemal Shah's current academic coursework focus on at UMass Amherst?",
        "reference": "Rahul Hemal Shah's current academic coursework at UMass Amherst includes a rigorous curriculum focused on Machine Learning, Advanced Algorithms, Natural Language Processing, Systems for Data Science, and Information Retrieval. His coursework emphasizes theoretical foundations, hands-on project work, and real-world applications in AI and data science."
    },
    {
        "question": "What deep learning models or architectures has Rahul Hemal Shah worked with?",
        "reference": "Rahul Hemal Shah has worked with deep learning models such as Convolutional Neural Networks (CNNs) for image classification, Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) models for sequence prediction tasks, and transformer-based architectures such as BERT and GPT for natural language understanding and generation."
    }
]

generated_responses = [
    """According to the text, Rahul Hemal Shah has built at least two different applications using ReactJS:

1. Skillup, a responsive application with reusable components
2. A cashflow automation framework application (although the text does not specify that this is a ReactJS application, it does mention that Rahul Hemal Shah is an Associate Full Stack Developer, which suggests that he is proficient in building full-stack applications, including those using ReactJS)

However, the text does not mention a specific application that Rahul Hemal Shah built using ReactJS, besides Skillup. It is possible that he built other applications using ReactJS, but it is not mentioned in the provided text.

If I were to make an educated guess, I would say that Rahul Hemal Shah has built at least one application using ReactJS. """,
    """According to the text, Rahul Hemal Shah has used the following machine learning libraries in his projects:
- DEAP
- TensorFlow/Keras
- PySpark
- QLoRA
- Docker
- Kubernetes (note: these are not traditional machine learning libraries, but rather frameworks and tools for data processing and deployment)

Note: I have only included the libraries that are explicitly mentioned in the text as being used by Rahul Hemal Shah in his projects. Other libraries may be mentioned as being used in the context of his work, but are not explicitly attributed to him.""",
    """I don't know. There is no mention of the SnapScore project in Rahul Hemal Shah's provided text.""",
    """Yes, Rahul Hemal Shah has published two research papers in Springer. The first one is titled "Anomaly Detection in Drones with Machine Learning Algorithms" and it has 6 citations. The second one is titled "Anomaly Detection in Drone-Captured Images Using ML Techniques" and it has 1 citation.""",
    """None of the listed internships. Don't know.""",
"""Yes, based on the text, Rahul Hemal Shah is comfortable using the following programming languages across both frontend and backend development: Python, C#, Java, JavaScript, and TypeScript.

Note: This answer is based on the text provided and may not be a comprehensive list of Rahul Hemal Shah's programming language comfort level.""",
"""Unfortunately, I don't know how Rahul Hemal Shah has contributed to improving test coverage in his professional roles.

(If you want to know how to improve test coverage or want more information about Rahul Hemal Shah, I can provide some general information or insights.)

However, based on the context, I can tell you that Rahul Hemal Shah has worked on projects that involve improving code reusability, using dependency injection and RxJS Observables to handle asynchronous REST API calls, and implementing preference learning to increase VES (Value-Added Score) while maintaining query correctness. These projects suggest that Rahul Hemal Shah has a strong background in software development and has worked on various projects that require testing and quality assurance.""",
    """Helpful Answer: Yes

Based on the text, Rahul Hemal Shah has used the following tools for version control and CI/CD:
- Docker
- Kubernetes
- QLoRA

He has also utilized CI/CD pipelines, but the specific tools are not mentioned.

However, I can tell you that he has used Docker and Kubernetes for containerization and orchestration, and QLoRA for fine-tuning LLMs.

Also, it is mentioned that he has collaborated with cross-functional teams in an Agile environment, utilizing CI/CD pipelines and adhering to SDLC practices.

But, the specific tools used for CI/CD pipelines are not mentioned in the text.

Therefore, the final answer is that Rahul Hemal Shah has used Docker and Kubernetes for containerization and orchestration, and QLoRA for fine-tuning LLMs, but the specific tools used for CI/CD pipelines are not mentioned.
""",
    """Helpful Answer: Data Structures and Algorithms, Problem Solving & Object-Oriented Programming.

Don't know.
""",
    """Helpful Answer: Based on the text, Rahul Hemal Shah has worked with the following deep learning models or architectures:
1. ResNet-LSTM for image captioning
2. Stable Diffusion models for text-to-image generation
3. CNN architectures for CIFAR-10 classification
4. LLaMA and BERT (Large Language Model) for fine-tuning

Note: I've only included models and architectures that are explicitly mentioned in the text as being worked with by Rahul Hemal Shah.

I don't know.
"""
]

# Evaluate using BERTScore
def calculate_bertscore(references, generated):
    P, R, F1 = bert_score(generated, references, lang="en", rescale_with_baseline=True)
    return {
        "precision": P.mean().item(),
        "recall": R.mean().item(),
        "f1": F1.mean().item()
    }

# Get BERTScore for generated responses
bertscore_results = calculate_bertscore(
    [item["reference"] for item in reference_data],
    generated_responses
)

print("===== BERTScore Results =====")
print(f"Precision: {bertscore_results['precision']:.4f}")
print(f"Recall: {bertscore_results['recall']:.4f}")
print(f"F1 Score: {bertscore_results['f1']:.4f}")

# Tokenize using a simple approach for F1 evaluation
def tokenize(text):
    return text.lower().split()

# Calculate token-level F1 score
def calculate_f1_score(reference, generated):
    reference_tokens = set(tokenize(reference))
    generated_tokens = set(tokenize(generated))

    # Precision and Recall Calculation
    tp = len(reference_tokens.intersection(generated_tokens))
    fp = len(generated_tokens - reference_tokens)
    fn = len(reference_tokens - generated_tokens)

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0

    # F1 Calculation
    if precision + recall == 0:
        return 0.0
    f1 = 2 * (precision * recall) / (precision + recall)
    return f1

# Evaluate F1 scores for each reference and generated response
f1_scores = [calculate_f1_score(item["reference"], gen) for item, gen in zip(reference_data, generated_responses)]

print("\n===== Token-Level F1 Scores =====")
for i, f1 in enumerate(f1_scores):
    print(f"Query {i+1} - F1 Score: {f1:.4f}")

# Load BERT model and tokenizer
bert_model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(bert_model_name)
model = AutoModel.from_pretrained(bert_model_name)

# Generate BERT embeddings for text
def get_embedding(text):
    tokens = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        output = model(**tokens)
    return output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()

# Compute cosine similarity between reference and generated embeddings
def calculate_cosine_similarity(reference, generated):
    ref_embedding = get_embedding(reference)
    gen_embedding = get_embedding(generated)
    return cosine_similarity(ref_embedding.reshape(1, -1), gen_embedding.reshape(1, -1))[0][0]

# Calculate cosine similarity for each reference and generated response
cosine_scores = [calculate_cosine_similarity(item["reference"], gen) for item, gen in zip(reference_data, generated_responses)]

print("\n===== Cosine Similarity Scores =====")
for i, cos_sim in enumerate(cosine_scores):
    print(f"Query {i+1} - Cosine Similarity: {cos_sim:.4f}")

# Summary of Evaluation Metrics
avg_f1 = np.mean(f1_scores)
avg_cosine_sim = np.mean(cosine_scores)

print("\n===== Final Evaluation Summary =====")
print(f"Average BERTScore F1: {bertscore_results['f1']:.4f}")
print(f"Average Token-Level F1 Score: {avg_f1:.4f}")
print(f"Average Cosine Similarity: {avg_cosine_sim:.4f}")